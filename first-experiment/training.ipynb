{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d295283f-5726-4c2c-ac78-2b2bfa33ec38",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmaller_dataset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "df=pd.read_csv(\"smaller_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae126487-bace-4a73-a76c-b81f53e529f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#df_encoded=pd.get_dummies(df,columns=[\"NAZ_LOKALI\"])\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#takto sa mi podarilo vymazat UNNAMED stlpec na pozicii 1. atiez NAZ_LOKALI na pozicii 475.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df_encoded \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mdrop([df\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m]], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m df_encoded\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#df_encoded=pd.get_dummies(df,columns=[\"NAZ_LOKALI\"])\n",
    "#takto sa mi podarilo vymazat UNNAMED stlpec na pozicii 1. atiez NAZ_LOKALI na pozicii 475.\n",
    "df_encoded = df.drop([df.columns[0]], axis=1)\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e14efa54-566b-4442-bb28-d1e66b6b6349",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_encoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_encoded\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmaller_dataset_NAZ_LOKALIT.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_encoded' is not defined"
     ]
    }
   ],
   "source": [
    "df_encoded.to_csv(\"smaller_dataset_NAZ_LOKALIT.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20594974-710f-4904-9182-537d4607496b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'b1__', 'b2__', 'b3__', 'b4__', 'b5__', 'b6__', 'b7__', 'b8__', 'b9__', 'b10__', 'b11__', 'b12__', 'b13__', 'b14__', 'b15__', 'b16__', 'b17__', 'b18__', 'b19__', 'b20__', 'b21__', 'b22__', 'b23__', 'b24__', 'b25__', 'b26__', 'b27__', 'b28__', 'b29__', 'b30__', 'b31__', 'b32__', 'b33__', 'b34__', 'b35__', 'b36__', 'b37__', 'b38__', 'b39__', 'b40__', 'b41__', 'b42__', 'b43__', 'b44__', 'b45__', 'b46__', 'b47__', 'b48__', 'b49__', 'b50__', 'b51__', 'b52__', 'b53__', 'b54__', 'b55__', 'b56__', 'b57__', 'b58__', 'b59__', 'b60__', 'b61__', 'b62__', 'b63__', 'b64__', 'b65__', 'b66__', 'b67__', 'b68__', 'b69__', 'b70__', 'b71__', 'b72__', 'b73__', 'b74__', 'b75__', 'b76__', 'b77__', 'b78__', 'b79__', 'b80__', 'b81__', 'b82__', 'b83__', 'b84__', 'b85__', 'b86__', 'b87__', 'b88__', 'b89__', 'b90__', 'b91__', 'b92__', 'b93__', 'b94__', 'b95__', 'b96__', 'b97__', 'b98__', 'b99__', 'b100__', 'b101__', 'b102__', 'b103__', 'b104__', 'b105__', 'b106__', 'b107__', 'b108__', 'b109__', 'b110__', 'b111__', 'b112__', 'b113__', 'b114__', 'b115__', 'b116__', 'b117__', 'b118__', 'b119__', 'b120__', 'b121__', 'b122__', 'b123__', 'b124__', 'b125__', 'b126__', 'b127__', 'b128__', 'b129__', 'b130__', 'b131__', 'b132__', 'b133__', 'b134__', 'b135__', 'b136__', 'b137__', 'b138__', 'b139__', 'b140__', 'b141__', 'b142__', 'b143__', 'b144__', 'b145__', 'b146__', 'b147__', 'b148__', 'b149__', 'b150__', 'b151__', 'b152__', 'b153__', 'b154__', 'b155__', 'b156__', 'b157__', 'b158__', 'b159__', 'b160__', 'b161__', 'b162__', 'b163__', 'b164__', 'b165__', 'b166__', 'b167__', 'b168__', 'b169__', 'b170__', 'b171__', 'b172__', 'b173__', 'b174__', 'b175__', 'b176__', 'b177__', 'b178__', 'b179__', 'b180__', 'b181__', 'b182__', 'b183__', 'b184__', 'b185__', 'b186__', 'b187__', 'b188__', 'b189__', 'b190__', 'b191__', 'b192__', 'b193__', 'b194__', 'b195__', 'b196__', 'b197__', 'b198__', 'b199__', 'b200__', 'b201__', 'b202__', 'b203__', 'b204__', 'b205__', 'b206__', 'b207__', 'b208__', 'b209__', 'b210__', 'b211__', 'b212__', 'b213__', 'b214__', 'b215__', 'b216__', 'b217__', 'b218__', 'b219__', 'b220__', 'b221__', 'b222__', 'b223__', 'b224__', 'b225__', 'b226__', 'b227__', 'b228__', 'b229__', 'b230__', 'b231__', 'b232__', 'b233__', 'b234__', 'b235__', 'b236__', 'b237__', 'b238__', 'b239__', 'b240__', 'b241__', 'b242__', 'b243__', 'b244__', 'b245__', 'b246__', 'b247__', 'b248__', 'b249__', 'b250__', 'b251__', 'b252__', 'b253__', 'b254__', 'b255__', 'b256__', 'b257__', 'b258__', 'b259__', 'b260__', 'b261__', 'b262__', 'b263__', 'b264__', 'b265__', 'b266__', 'b267__', 'b268__', 'b269__', 'b270__', 'b271__', 'b272__', 'b273__', 'b274__', 'b275__', 'b276__', 'b277__', 'b278__', 'b279__', 'b280__', 'b281__', 'b282__', 'b283__', 'b284__', 'b285__', 'b286__', 'b287__', 'b288__', 'b289__', 'b290__', 'b291__', 'b292__', 'b293__', 'b294__', 'b295__', 'b296__', 'b297__', 'b298__', 'b299__', 'b300__', 'b301__', 'b302__', 'b303__', 'b304__', 'b305__', 'b306__', 'b307__', 'b308__', 'b309__', 'b310__', 'b311__', 'b312__', 'b313__', 'b314__', 'b315__', 'b316__', 'b317__', 'b318__', 'b319__', 'b320__', 'b321__', 'b322__', 'b323__', 'b324__', 'b325__', 'b326__', 'b327__', 'b328__', 'b329__', 'b330__', 'b331__', 'b332__', 'b333__', 'b334__', 'b335__', 'b336__', 'b337__', 'b338__', 'b339__', 'b340__', 'b341__', 'b342__', 'b343__', 'b344__', 'b345__', 'b346__', 'b347__', 'b348__', 'b349__', 'b350__', 'b351__', 'b352__', 'b353__', 'b354__', 'b355__', 'b356__', 'b357__', 'b358__', 'b359__', 'b360__', 'b361__', 'b362__', 'b363__', 'b364__', 'b365__', 'b366__', 'b367__', 'b368__', 'b369__', 'b370__', 'b371__', 'b372__', 'b373__', 'b374__', 'b375__', 'b376__', 'b377__', 'b378__', 'b379__', 'b380__', 'b381__', 'b382__', 'b383__', 'b384__', 'b385__', 'b386__', 'b387__', 'b388__', 'b389__', 'b390__', 'b391__', 'b392__', 'b393__', 'b394__', 'b395__', 'b396__', 'b397__', 'b398__', 'b399__', 'b400__', 'b401__', 'b402__', 'b403__', 'b404__', 'b405__', 'b406__', 'b407__', 'b408__', 'b409__', 'b410__', 'b411__', 'b412__', 'b413__', 'b414__', 'b415__', 'b416__', 'b417__', 'b418__', 'b419__', 'b420__', 'b421__', 'b422__', 'b423__', 'b424__', 'b425__', 'b426__', 'b427__', 'b428__', 'b429__', 'b430__', 'b431__', 'b432__', 'b433__', 'b434__', 'b435__', 'b436__', 'b437__', 'b438__', 'b439__', 'b440__', 'b441__', 'b442__', 'b443__', 'b444__', 'b445__', 'b446__', 'b447__', 'b448__', 'b449__', 'b450__', 'b451__', 'b452__', 'b453__', 'b454__', 'b455__', 'b456__', 'b457__', 'b458__', 'b459__', 'b460__', 'b461__', 'b462__', 'b463__', 'b464__', 'b465__', 'b466__', 'b467__', 'b468__', 'b469__', 'b470__', 'b471__', 'b472__', 'b473__', 'b474__', 'NAZ_LOKALI', 'DRUH_POVR']\n",
      "475\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())\n",
    "position = df.columns.get_loc('NAZ_LOKALI')\n",
    "print(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "597d632d-8ec1-41cc-a922-a9d5418eef19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "511da8d9-16fc-4797-9a66-ce682c02c270",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_encoded.drop(columns=[\"DRUH_POVR\"])\n",
    "y=df_encoded[\"DRUH_POVR\"]\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_encoded = pd.Series(y_encoded, index=y.index, name='Encoded_Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "976dc02e-4989-4aa1-b515-5388060997bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y_encoded,test_size=0.2,stratify=y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "294ea931-6b2e-41c6-b691-e69fd8034ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoded_Y\n",
       "12    7066\n",
       "4     3630\n",
       "7     3054\n",
       "10    2046\n",
       "16    1553\n",
       "0     1407\n",
       "1     1206\n",
       "8     1102\n",
       "3     1034\n",
       "15    1007\n",
       "14     857\n",
       "5      617\n",
       "9      420\n",
       "2      334\n",
       "6      322\n",
       "11     301\n",
       "13     203\n",
       "17     201\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ced7f33-956f-43a1-b7d6-39a1ff1bdf5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoded_Y\n",
       "12    1767\n",
       "4      908\n",
       "7      764\n",
       "10     512\n",
       "16     388\n",
       "0      352\n",
       "1      302\n",
       "8      275\n",
       "3      258\n",
       "15     252\n",
       "14     214\n",
       "5      154\n",
       "9      105\n",
       "2       83\n",
       "6       80\n",
       "11      75\n",
       "13      51\n",
       "17      50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "752d46a1-add6-47bb-b190-2821ad98e882",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = X_train.to_numpy()\n",
    "X_test_np = X_test.to_numpy()\n",
    "y_train_np = y_train.to_numpy()\n",
    "y_test_np = y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fa5f95af-d970-45b5-9707-25c7cdd9ea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = tf.data.Dataset.from_tensor_slices((X_train_np, y_train_np))\n",
    "#test_dataset = tf.data.Dataset.from_tensor_slices((X_test_np, y_test_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1e95471c-c77e-4620-8b39-203dc5e90fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(set(y_train))\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu'), \n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax'), \n",
    "])\n",
    "X_train_np = X_train.to_numpy()\n",
    "X_test_np = X_test.to_numpy()\n",
    "y_train_np = y_train.to_numpy()\n",
    "y_test_np = y_train.to_numpy()\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), optimizer=tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0e82376e-f25e-4530-a3b5-8f03dff1d47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b1__</th>\n",
       "      <th>b2__</th>\n",
       "      <th>b3__</th>\n",
       "      <th>b4__</th>\n",
       "      <th>b5__</th>\n",
       "      <th>b6__</th>\n",
       "      <th>b7__</th>\n",
       "      <th>b8__</th>\n",
       "      <th>b9__</th>\n",
       "      <th>b10__</th>\n",
       "      <th>...</th>\n",
       "      <th>b465__</th>\n",
       "      <th>b466__</th>\n",
       "      <th>b467__</th>\n",
       "      <th>b468__</th>\n",
       "      <th>b469__</th>\n",
       "      <th>b470__</th>\n",
       "      <th>b471__</th>\n",
       "      <th>b472__</th>\n",
       "      <th>b473__</th>\n",
       "      <th>b474__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22310</th>\n",
       "      <td>0.001517</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>0.001907</td>\n",
       "      <td>0.001848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.857770e-05</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10817</th>\n",
       "      <td>0.004717</td>\n",
       "      <td>0.004314</td>\n",
       "      <td>0.004668</td>\n",
       "      <td>0.004511</td>\n",
       "      <td>0.005281</td>\n",
       "      <td>0.004716</td>\n",
       "      <td>0.004778</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>0.004609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>7.661060e-04</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>0.000827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>0.002558</td>\n",
       "      <td>0.003251</td>\n",
       "      <td>0.003088</td>\n",
       "      <td>0.003068</td>\n",
       "      <td>0.003437</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.003406</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>0.003276</td>\n",
       "      <td>0.003890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>1.160390e-04</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10903</th>\n",
       "      <td>0.006837</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>0.007087</td>\n",
       "      <td>0.007385</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.007538</td>\n",
       "      <td>0.007531</td>\n",
       "      <td>0.008180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11007</th>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>0.001899</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>3.827480e-07</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 474 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           b1__      b2__      b3__      b4__      b5__      b6__      b7__  \\\n",
       "22310  0.001517  0.001620  0.001977  0.001859  0.001687  0.001734  0.001395   \n",
       "10817  0.004717  0.004314  0.004668  0.004511  0.005281  0.004716  0.004778   \n",
       "2147   0.002558  0.003251  0.003088  0.003068  0.003437  0.003322  0.003406   \n",
       "10903  0.006837  0.006851  0.007087  0.007385  0.007406  0.007498  0.007299   \n",
       "11007  0.001796  0.001923  0.002056  0.002435  0.001899  0.002326  0.002197   \n",
       "\n",
       "           b8__      b9__     b10__  ...    b465__    b466__    b467__  \\\n",
       "22310  0.001727  0.001907  0.001848  ...  0.000087  0.000000  0.000146   \n",
       "10817  0.004444  0.004322  0.004609  ...  0.000413  0.000539  0.000490   \n",
       "2147   0.003446  0.003276  0.003890  ...  0.000102  0.000029  0.000103   \n",
       "10903  0.007538  0.007531  0.008180  ...  0.000000  0.000000  0.000000   \n",
       "11007  0.002122  0.001887  0.002235  ...  0.000029  0.000097  0.000000   \n",
       "\n",
       "         b468__        b469__    b470__    b471__    b472__    b473__  \\\n",
       "22310  0.000000  9.857770e-05  0.000040  0.000165  0.000051  0.000000   \n",
       "10817  0.000455  7.661060e-04  0.000789  0.000894  0.000795  0.000847   \n",
       "2147   0.000051  1.160390e-04  0.000092  0.000167  0.000160  0.000191   \n",
       "10903  0.000000  0.000000e+00  0.000000  0.000000  0.000000  0.000000   \n",
       "11007  0.000075  3.827480e-07  0.000139  0.000020  0.000025  0.000025   \n",
       "\n",
       "         b474__  \n",
       "22310  0.000514  \n",
       "10817  0.000827  \n",
       "2147   0.000063  \n",
       "10903  0.000000  \n",
       "11007  0.000065  \n",
       "\n",
       "[5 rows x 474 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "#print(X_train.dtypes)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f38f67c8-6abc-46ce-864f-55004a2191d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m824/824\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - loss: 2.5079\n",
      "Epoch 2/5\n",
      "\u001b[1m824/824\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step - loss: 2.2087\n",
      "Epoch 3/5\n",
      "\u001b[1m824/824\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - loss: 2.0975\n",
      "Epoch 4/5\n",
      "\u001b[1m824/824\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - loss: 2.0281\n",
      "Epoch 5/5\n",
      "\u001b[1m824/824\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 782us/step - loss: 1.9589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x73a064569690>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ca5acd5d-70da-4728-93dd-41461d6e1f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['DL', 'SM', 'SM', ..., 'DL', 'DL', 'DL'], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_predict = model.predict(X_test)\n",
    "y_predict = np.argmax(y_predict, axis=1)\n",
    "y_pred_text = label_encoder.inverse_transform(y_predict)\n",
    "y_pred_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c7566b95-4b4d-4ddc-a867-2f591f27787c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194eec8a-4e5d-4422-b500-a1c1a95a3ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
